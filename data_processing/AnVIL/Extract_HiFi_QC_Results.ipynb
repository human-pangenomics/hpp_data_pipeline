{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract HiFi QC Data<a class=\"tocSkip\">\n",
    "\n",
    "**This notebook reads in data from NTSM and ReadStats WDLS (stored in data tables). This is part of the HiFi QC process.**\n",
    "\n",
    "**Below are the steps taken in this notebook:**\n",
    "1. Import Statements & Global Variable Definitions\n",
    "2. Define Functions\n",
    "3. Read In Sample Names\n",
    "4. Create Dataframe Of Files\n",
    "5. Examine results\n",
    "\n",
    "**Note**: These results are not written back to the data tables or to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements & Global Variable Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install gcsfs\n",
    "## capture CANNOT have comments above it\n",
    "## For reading CSVs stored in Google Cloud (without downloading them first)\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade --no-cache-dir --force-reinstall terra-pandas\n",
    "%pip install --upgrade --no-cache-dir  --force-reinstall git+https://github.com/DataBiosphere/terra-notebook-utils\n",
    "## For reading/writing data tables into pandas data frames\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecloud import fiss\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import terra_pandas as tp\n",
    "import os                 \n",
    "import subprocess       \n",
    "import re                 \n",
    "import io\n",
    "import gcsfs\n",
    "\n",
    "from typing import Any, Callable, List, Optional\n",
    "from terra_notebook_utils import table, WORKSPACE_NAME, WORKSPACE_GOOGLE_PROJECT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Google billing project name and workspace name for current workspace\n",
    "PROJECT = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE =os.path.basename(os.path.dirname(os.getcwd()))\n",
    "bucket = os.environ['WORKSPACE_BUCKET'] + \"/\"\n",
    "\n",
    "# Verify that we've captured the environment variables\n",
    "print(\"Billing project: \" + PROJECT)\n",
    "print(\"Workspace: \" + WORKSPACE)\n",
    "print(\"Workspace storage bucket: \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract NTSM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in NTSM Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsm_df = tp.table_to_dataframe(\"ntsm\", workspace=WORKSPACE, workspace_namespace=PROJECT)\n",
    "\n",
    "ntsm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NTSM Output & Write To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsm_df['ntsm_score'] = np.nan\n",
    "ntsm_df['result']     = np.nan\n",
    "\n",
    "for index, row in ntsm_df.iterrows():\n",
    "\n",
    "        sample_ntsm_fp = row['ntsm_eval_out']\n",
    "        sample_ntsm_df = pd.read_csv(sample_ntsm_fp, header=None, sep='\\t')\n",
    "\n",
    "        ntsm_df.loc[index,'ntsm_score'] = sample_ntsm_df.iloc[0][2]\n",
    "        ntsm_df.loc[index,'result'] = sample_ntsm_df[3].astype('str')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## How many rows don't match? (Should be 0)\n",
    "sum(ntsm_df['result'] != 'Similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ReadStats Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in ReadStats Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats_df = tp.table_to_dataframe(\"readstats\", workspace=WORKSPACE, workspace_namespace=PROJECT)\n",
    "\n",
    "readstats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ReadStats Output & Write To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats_df['output']   = np.nan\n",
    "\n",
    "for index, row in readstats_df.iterrows():\n",
    "\n",
    "        sample_readstats_fp = row['ReadStatsReport']\n",
    "        #sample_readstats_fn = os.path.basename(sample_readstats_fp)\n",
    "\n",
    "        #! gsutil cp {sample_readstats_fp} .\n",
    "        \n",
    "        sample_readstats_df = pd.read_csv(sample_readstats_fp, header=None, sep='\\t')\n",
    "\n",
    "        ## Just look at sample-level metrics\n",
    "        sample_readstats_df = sample_readstats_df[sample_readstats_df[0]=='sample.fastq']\n",
    "\n",
    "        ## Get rid of extra row\n",
    "        sample_readstats_df = sample_readstats_df.iloc[1: , :]\n",
    "\n",
    "\n",
    "        sample_coverage = sample_readstats_df[sample_readstats_df[1] == 'total_Gbp'][2]\n",
    "        readstats_df.loc[index,'output'] = float(sample_coverage.values[0])\n",
    "\n",
    "        \n",
    "readstats_df['coverage'] = readstats_df['output']/3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readstats_df.shape\n",
    "len(readstats_df['sample'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum coverage by sample\n",
    "for sample in (readstats_df['sample'].unique()):\n",
    "    total_coverage = readstats_df.loc[readstats_df['sample'] == sample, 'coverage'].sum()\n",
    "    if total_coverage < 35:\n",
    "        print(sample, round(total_coverage,2))\n",
    "# this should output nothing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: put these in a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
