{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ONT QC Data<a class=\"tocSkip\">\n",
    "\n",
    "**This notebook reads in data from NTSM and Coverage WDLS (stored in data tables). This is part of the ONT QC process.**\n",
    "\n",
    "**Below are the steps taken in this notebook:**\n",
    "1. Import Statements & Global Variable Definitions\n",
    "2. Define Functions\n",
    "3. Read In Sample Names\n",
    "4. Create Dataframe Of Files\n",
    "5. Examine results\n",
    "\n",
    "**Note**: These results are not written back to the data tables or to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements & Global Variable Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## May need to restart kernel after the following installs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install gcsfs\n",
    "## capture CANNOT have comments above it\n",
    "## For reading CSVs stored in Google Cloud (without downloading them first)\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade --no-cache-dir --force-reinstall terra-pandas\n",
    "%pip install --upgrade --no-cache-dir  --force-reinstall git+https://github.com/DataBiosphere/terra-notebook-utils\n",
    "## For reading/writing data tables into pandas data frames\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecloud import fiss\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import terra_pandas as tp\n",
    "import os                 \n",
    "import subprocess       \n",
    "import re                 \n",
    "import io\n",
    "import gcsfs\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from typing import Any, Callable, List, Optional\n",
    "from terra_notebook_utils import table, WORKSPACE_NAME, WORKSPACE_GOOGLE_PROJECT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Google billing project name and workspace name for current workspace\n",
    "PROJECT = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE =os.path.basename(os.path.dirname(os.getcwd()))\n",
    "bucket = os.environ['WORKSPACE_BUCKET'] + \"/\"\n",
    "\n",
    "# Verify that we've captured the environment variables\n",
    "print(\"Billing project: \" + PROJECT)\n",
    "print(\"Workspace: \" + WORKSPACE)\n",
    "print(\"Workspace storage bucket: \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract NTSM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in NTSM Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsm_df = tp.table_to_dataframe(\"ntsm\", workspace=WORKSPACE, workspace_namespace=PROJECT)\n",
    "\n",
    "ntsm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NTSM Output & Write To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsm_df['ntsm_score'] = np.nan\n",
    "ntsm_df['result']     = np.nan\n",
    "\n",
    "for index, row in ntsm_df.iterrows():\n",
    "\n",
    "        sample_ntsm_fp = row['ntsm_eval_out']\n",
    "        sample_ntsm_df = pd.read_csv(sample_ntsm_fp, header=None, sep='\\t')\n",
    "\n",
    "        ntsm_df.loc[index,'ntsm_score'] = sample_ntsm_df.iloc[0][2]\n",
    "        ntsm_df.loc[index,'result'] = sample_ntsm_df[3].astype('str')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## How many rows don't match? (Should be 0)\n",
    "sum(ntsm_df['result'] != 'Similar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract ReadStats Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in ReadStats Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covstats_df = tp.table_to_dataframe(\"covstats\", workspace=WORKSPACE, workspace_namespace=PROJECT)\n",
    "\n",
    "covstats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ReadStats Output & Write To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_files = list(covstats_df['pass_summary_stats']) + list(covstats_df['fail_summary_stats'])\n",
    "#summary_files=['gs://fc-72c79fce-944a-4bf1-a8d1-717ecd7a29a3/submissions/84baaeda-5840-4d9b-93da-8c6ede10596d/run_calc_ont_stats/e1842c56-7bc2-46ad-9196-62deb717a086/call-calc_ont_summary_stats/cacheCopy/glob-f0d314809f0b58a96bee1f8f36b45ca1/12_08_21_R941_HG00423_1_Guppy_6.4.6_450bps_modbases_5mc_cg_sup_prom.pass_summary_stats.txt','gs://fc-72c79fce-944a-4bf1-a8d1-717ecd7a29a3/submissions/84baaeda-5840-4d9b-93da-8c6ede10596d/run_calc_ont_stats/129377bc-f790-44b9-b6a0-ab8bbba9ec0d/call-calc_ont_summary_stats/glob-f0d314809f0b58a96bee1f8f36b45ca1/07_20_21_R941_HG02698_3_Guppy_6.5.7_450bps_modbases_5mc_cg_sup_prom.pass_summary_stats.txt','gs://fc-72c79fce-944a-4bf1-a8d1-717ecd7a29a3/submissions/84baaeda-5840-4d9b-93da-8c6ede10596d/run_calc_ont_stats/4e5a1164-d9e0-48d3-bed1-d3c25710c32b/call-calc_ont_summary_stats/attempt-2/glob-f0d314809f0b58a96bee1f8f36b45ca1/08_17_21_R941_HG02735_1_Guppy_6.5.7_450bps_modbases_5mc_cg_sup_prom.pass_summary_stats.txt', 'gs://fc-72c79fce-944a-4bf1-a8d1-717ecd7a29a3/submissions/84baaeda-5840-4d9b-93da-8c6ede10596d/run_calc_ont_stats/304ebe1c-7c06-4b5d-a9ed-c898f29fcf95/call-calc_ont_summary_stats/attempt-2/glob-f0d314809f0b58a96bee1f8f36b45ca1/08_17_21_R941_HG02735_2_Guppy_6.5.7_450bps_modbases_5mc_cg_sup_prom.pass_summary_stats.txt']\n",
    "#print(summary_files)\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each summary file and append its contents to the combined dataframe\n",
    "for summary in summary_files:\n",
    "    df = pd.read_csv(summary, sep='\\t')\n",
    "    #df['pass_summary_stats'] = summary\n",
    "    #df['sample'] = df['File'].str.split(pat=\"_\").str[4] \n",
    "    df.insert(1, 'sample', df['File'].str.split(pat=\"_\").str[4])\n",
    "    df.insert(2, 'flowcell', df['File'].str.split(pat=\"_\").str[4:6].str.join('_'))\n",
    "    df['File'] = df['File'].str.replace('\\[\\'', '').str.replace('\\'\\]', '').str.replace('txt','bam')\n",
    "    summary_df = pd.concat([summary_df, df])\n",
    "\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.shape\n",
    "len(covstats_df['sample'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum coverage by sample\n",
    "for sample in (summary_df['sample'].unique()):\n",
    "    total_coverage = summary_df.loc[summary_df['sample'] == sample, 'coverage'].sum()\n",
    "    if total_coverage < 60:\n",
    "        print(sample, round(total_coverage,2))\n",
    "# this should output nothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum coverage by sample\n",
    "for sample in (summary_df['sample'].unique()):\n",
    "    total_100kb_coverage = summary_df.loc[summary_df['sample'] == sample, '100kb+'].sum()\n",
    "    if total_100kb_coverage < 30:\n",
    "        print(sample, round(total_100kb_coverage,2))\n",
    "# this should output nothing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check tables, then export to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "outSumm = os.path.join(bucket, WORKSPACE + '_summary.tsv')\n",
    "summary_df.to_csv(outSumm, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "outNTSM = os.path.join(bucket, WORKSPACE + '_NTSM.tsv')\n",
    "ntsm_df.to_csv(outNTSM, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
